WEBVTT
Kind: captions
Language: en

00:00:00.140 --> 00:00:01.530
JAKE: Who doesn't care
about web security?

00:00:01.530 --> 00:00:01.980
CHRIS PALMER: Right.

00:00:01.980 --> 00:00:03.150
JAKE: Everyone should
care about web security.

00:00:03.150 --> 00:00:03.480
CHRIS PALMER: What
kind of maniac

00:00:03.480 --> 00:00:04.470
would not care
about web security?

00:00:04.470 --> 00:00:05.345
JAKE: It's very true.

00:00:05.345 --> 00:00:07.611
CHRIS PALMER: I can't
even imagine that.

00:00:07.611 --> 00:00:09.042
[MUSIC PLAYING]

00:00:12.381 --> 00:00:14.785
JAKE: Who are you, and why?

00:00:14.785 --> 00:00:16.700
EMILY SCHECTER: My name
is Emily Schechter.

00:00:16.700 --> 00:00:18.990
I'm product manager on
the Chrome Security Team,

00:00:18.990 --> 00:00:23.032
and because I feel like it.

00:00:23.032 --> 00:00:24.990
SURMA: That is probably
one of the best reasons

00:00:24.990 --> 00:00:27.310
to give for existing.

00:00:27.310 --> 00:00:27.810
JAKE: And?

00:00:27.810 --> 00:00:28.680
CHRIS PALMER: I'm Chris Palmer.

00:00:28.680 --> 00:00:30.820
I'm an engineer on the
Chrome Security Team.

00:00:30.820 --> 00:00:32.095
And I also feel like it.

00:00:32.095 --> 00:00:34.470
JAKE: I always think of like,
the security team at Google

00:00:34.470 --> 00:00:37.790
as being kind of
like the cool kids.

00:00:37.790 --> 00:00:38.750
You're sort of in--

00:00:38.750 --> 00:00:40.260
SURMA: To me, it's
like the A-team.

00:00:40.260 --> 00:00:41.971
JAKE: Yeah, like a
sort of secret room

00:00:41.971 --> 00:00:44.345
where stuff happens that we're
not allowed to hear about.

00:00:44.345 --> 00:00:45.636
SURMA: You know, black windows.

00:00:45.636 --> 00:00:46.510
You can't look in.

00:00:46.510 --> 00:00:51.120
JAKE: But I recently found
some security bugs in browsers

00:00:51.120 --> 00:00:54.260
recently, so I
feel like, am I in?

00:00:54.260 --> 00:00:55.020
What do I get?

00:00:55.020 --> 00:00:56.470
Do I get a goody bag?

00:00:56.470 --> 00:00:56.970
What's the--

00:00:56.970 --> 00:00:58.553
EMILY SCHECTER: You
get the secret key

00:00:58.553 --> 00:01:00.630
to the back room with
the black windows.

00:01:00.630 --> 00:01:01.430
JAKE: Oh.

00:01:01.430 --> 00:01:03.630
With these security
bugs I've seen,

00:01:03.630 --> 00:01:05.820
do I need to write
a PDF about it?

00:01:05.820 --> 00:01:08.100
Because it seems to me
like security engineers--

00:01:08.100 --> 00:01:10.890
SURMA: And do you need a logo,
because they nowadays launch

00:01:10.890 --> 00:01:12.000
with a website and a logo.

00:01:12.000 --> 00:01:12.240
Right?

00:01:12.240 --> 00:01:13.239
JAKE: A logo and a name.

00:01:13.239 --> 00:01:14.610
But why is it always PDF?

00:01:14.610 --> 00:01:17.070
Is it because HTML is
inherently insecure?

00:01:17.070 --> 00:01:18.742
So?

00:01:18.742 --> 00:01:19.242
[LAUGHING]

00:01:19.242 --> 00:01:21.420
So secure engineers
have to use PDF instead,

00:01:21.420 --> 00:01:22.560
which is a superior format?

00:01:22.560 --> 00:01:23.870
Is that?

00:01:23.870 --> 00:01:24.870
EMILY SCHECTER: I have--

00:01:24.870 --> 00:01:28.590
I mean, we do see a lot
of the names and logos.

00:01:28.590 --> 00:01:31.110
In our talk, we're going to
be talking about the Meltdown

00:01:31.110 --> 00:01:31.982
and Spectre--

00:01:31.982 --> 00:01:33.690
SURMA: Spectre, like
a nice spooky ghost.

00:01:33.690 --> 00:01:35.100
EMILY SCHECTER: A nice
spooky ghost, yeah, that--

00:01:35.100 --> 00:01:35.490
SURMA: That was the other one.

00:01:35.490 --> 00:01:36.810
EMILY SCHECTER: That came
out with a whole website

00:01:36.810 --> 00:01:38.172
with the whole explanation.

00:01:38.172 --> 00:01:39.630
SURMA: That was
some good branding.

00:01:39.630 --> 00:01:41.130
Like, that day was exciting.

00:01:41.130 --> 00:01:43.490
JAKE: What's your talk title?

00:01:43.490 --> 00:01:45.760
CHRIS PALMER: What
is our talk title?

00:01:45.760 --> 00:01:45.890
JAKE: Just for the record--

00:01:45.890 --> 00:01:47.223
CHRIS PALMER: I know what it is.

00:01:47.223 --> 00:01:49.299
JAKE: They're
speaking in an hour.

00:01:49.299 --> 00:01:51.590
SURMA: I mean, but you don't
speak out your talk title.

00:01:51.590 --> 00:01:53.820
CHRIS PALMER: Me and
metadata, like the title.

00:01:53.820 --> 00:01:57.570
EMILY SCHECTER: I believe
our title is "Lessons Learned

00:01:57.570 --> 00:02:00.390
from Spectre and Meltdown,
and What You Should

00:02:00.390 --> 00:02:02.146
Do To Keep Your Site Secure."

00:02:02.146 --> 00:02:03.270
SURMA: That's a long title.

00:02:03.270 --> 00:02:06.240
JAKE: Can you change it
to "Palmer and Schecter

00:02:06.240 --> 00:02:07.669
on Meltdown and Spectre,"

00:02:07.669 --> 00:02:08.460
CHRIS PALMER: Whoa.

00:02:08.460 --> 00:02:09.350
I can't believe we
didn't think of that.

00:02:09.350 --> 00:02:10.389
EMILY SCHECTER: Yeah,
that's actually shocking.

00:02:10.389 --> 00:02:11.140
CHRIS PALMER: That's better.

00:02:11.140 --> 00:02:11.280
EMILY SCHECTER: We should.

00:02:11.280 --> 00:02:12.090
We truly should.

00:02:12.090 --> 00:02:12.585
CHRIS PALMER: That's
actually way better.

00:02:12.585 --> 00:02:15.140
JAKE: So some people
would be unaware of what

00:02:15.140 --> 00:02:16.470
Meltdown and Spectre is.

00:02:16.470 --> 00:02:17.700
So--

00:02:17.700 --> 00:02:19.710
SURMA: Can you summarize
it in a sentence?

00:02:19.710 --> 00:02:21.007
Is that possible?

00:02:21.007 --> 00:02:22.840
EMILY SCHECTER: Do you
want to take a crack?

00:02:22.840 --> 00:02:23.855
CHRIS PALMER: Sure, sure.

00:02:23.855 --> 00:02:24.220
SURMA: Let's go.

00:02:24.220 --> 00:02:25.594
CHRIS PALMER: So
the impact of it

00:02:25.594 --> 00:02:29.304
is that you lose any
guarantee of confidentiality

00:02:29.304 --> 00:02:31.470
when you have two programs
running on the same chip.

00:02:31.470 --> 00:02:32.130
JAKE: That sounds bad.

00:02:32.130 --> 00:02:32.280
CHRIS PALMER: Oh, it's terrible.

00:02:32.280 --> 00:02:33.890
Yeah.

00:02:33.890 --> 00:02:35.910
I lost sleep over it.

00:02:35.910 --> 00:02:37.020
I literally did.

00:02:37.020 --> 00:02:40.380
JAKE: So, and this was like
a huge revelation, right?

00:02:40.380 --> 00:02:45.720
So I imagine just, one day,
you both went to work and like,

00:02:45.720 --> 00:02:46.370
what happened?

00:02:46.370 --> 00:02:46.750
Like, an email--

00:02:46.750 --> 00:02:48.291
SURMA: The windows
were turned black.

00:02:48.291 --> 00:02:49.860
JAKE: Or what happened?

00:02:49.860 --> 00:02:52.350
Everyone just-- someone
ran in screaming?

00:02:52.350 --> 00:02:53.500
How did that play out?

00:02:53.500 --> 00:02:54.630
EMILY SCHECTER: Well,
first, we took our key

00:02:54.630 --> 00:02:57.180
and we entered the secret
room with the black windows.

00:02:57.180 --> 00:02:58.530
No, no, no.

00:02:58.530 --> 00:02:59.617
Yeah.

00:02:59.617 --> 00:03:00.700
JAKE: Slide down the pole.

00:03:00.700 --> 00:03:02.200
EMILY SCHECTER:
Slide down the poles

00:03:02.200 --> 00:03:04.618
JAKE: Everyone to the
security, like, basement.

00:03:04.618 --> 00:03:06.530
[LAUGHING]

00:03:06.530 --> 00:03:09.060
SURMA: I think we're delivering
a good image of the security

00:03:09.060 --> 00:03:09.737
team.

00:03:09.737 --> 00:03:11.820
JAKE: So was it just one
morning, an email arrived

00:03:11.820 --> 00:03:13.390
of like, everything's broken?

00:03:13.390 --> 00:03:13.955
EMILY SCHECTER: Yeah, I think--

00:03:13.955 --> 00:03:14.610
CHRIS PALMER: That's what I got.

00:03:14.610 --> 00:03:14.820
EMILY SCHECTER: Yeah.

00:03:14.820 --> 00:03:16.153
It's essentially what I got too.

00:03:16.153 --> 00:03:19.920
And we ended up
having to really put

00:03:19.920 --> 00:03:22.590
in quite a lot of work
and collaboration,

00:03:22.590 --> 00:03:24.780
not only on the security
team, but it was really

00:03:24.780 --> 00:03:28.470
multiple teams across Chrome
and across Google, you

00:03:28.470 --> 00:03:30.960
know, everything from
the Google Cloud team

00:03:30.960 --> 00:03:33.040
to Chrome team, V8 team.

00:03:33.040 --> 00:03:37.470
You know, people working
on dev tools, and printing,

00:03:37.470 --> 00:03:38.670
and everything.

00:03:38.670 --> 00:03:39.300
SURMA: It affects everything.

00:03:39.300 --> 00:03:40.730
EMILY SCHECTER: Everyone all
really had to come together.

00:03:40.730 --> 00:03:43.144
SURMA: A processor is, in
a way, affected, I guess.

00:03:43.144 --> 00:03:44.935
JAKE: Most computers
have those these days.

00:03:44.935 --> 00:03:46.143
SURMA: Yeah, it's really sad.

00:03:46.143 --> 00:03:48.720
It was easier back in the
day without these processors.

00:03:48.720 --> 00:03:49.140
EMILY SCHECTER: Yeah.

00:03:49.140 --> 00:03:50.760
CHRIS PALMER: That's when
the problem was introduced.

00:03:50.760 --> 00:03:53.220
We also had to collaborate
with other companies

00:03:53.220 --> 00:03:57.240
in order to even figure
out what was going on.

00:03:57.240 --> 00:03:59.840
It took a while for people
to really get a grip mentally

00:03:59.840 --> 00:04:01.517
on what was happening.

00:04:01.517 --> 00:04:03.600
It takes a good couple of
days before you can even

00:04:03.600 --> 00:04:04.840
cope with it emotionally.

00:04:04.840 --> 00:04:06.510
JAKE: Well, that's
what I think as well.

00:04:06.510 --> 00:04:08.790
The way I'd imagine it
is the email is there,

00:04:08.790 --> 00:04:11.650
and it's like, oh, here's
this thing, the CPU thing.

00:04:11.650 --> 00:04:12.360
And I don't know.

00:04:12.360 --> 00:04:14.732
Maybe on the first
read, you'd be like, eh.

00:04:14.732 --> 00:04:16.440
And then just sort of
getting up, going--

00:04:16.440 --> 00:04:19.260
SURMA: And then it sinks in,
and you realize it's everything.

00:04:19.260 --> 00:04:21.635
JAKE: If you pour the coffee,
and then just half way back

00:04:21.635 --> 00:04:22.950
to the desk, drop the coffee.

00:04:22.950 --> 00:04:24.010
Wait a minute.

00:04:24.010 --> 00:04:25.407
Is this a big deal?

00:04:25.407 --> 00:04:27.240
EMILY SCHECTER: The
good news is that Chrome

00:04:27.240 --> 00:04:29.670
was working on this project
called site isolation

00:04:29.670 --> 00:04:32.520
for a really, really long time.

00:04:32.520 --> 00:04:35.680
Like, around the order
of five or seven years.

00:04:35.680 --> 00:04:37.389
And it turns out that
site isolation is--

00:04:37.389 --> 00:04:39.138
SURMA: And that's what
it says on the tin?

00:04:39.138 --> 00:04:40.125
It isolates the sites?

00:04:40.125 --> 00:04:40.890
EMILY SCHECTER: It
isolates the sites,

00:04:40.890 --> 00:04:43.080
which makes it actually
a really good way

00:04:43.080 --> 00:04:45.960
to mitigate some of the issues
that are caused by Spectre.

00:04:45.960 --> 00:04:48.270
What ends up happening is
that a tab can actually

00:04:48.270 --> 00:04:49.330
include multiple sites.

00:04:49.330 --> 00:04:49.830
Right?

00:04:49.830 --> 00:04:51.660
Like, a site could
have an iframe

00:04:51.660 --> 00:04:53.880
that's loading some
ads, stuff like that.

00:04:53.880 --> 00:04:56.160
So the way site
isolation changes things,

00:04:56.160 --> 00:04:58.024
is now each of those
sites are now isolated.

00:04:58.024 --> 00:04:59.940
SURMA: Circling back to
your event loop stuff,

00:04:59.940 --> 00:05:01.080
if they share an
event loop, it's

00:05:01.080 --> 00:05:02.880
hard to put them in different
processes, isn't it?

00:05:02.880 --> 00:05:03.540
JAKE: That's right.

00:05:03.540 --> 00:05:04.170
Yes.

00:05:04.170 --> 00:05:06.600
Yes, it is actually the
same thing in the same way

00:05:06.600 --> 00:05:09.590
that we have iframes in the
same event with its parent page.

00:05:09.590 --> 00:05:10.780
It's part of this problem.

00:05:10.780 --> 00:05:11.370
SURMA: Yeah.

00:05:11.370 --> 00:05:14.030
JAKE: So what do
developers need to change

00:05:14.030 --> 00:05:16.870
about how they write
sites in response

00:05:16.870 --> 00:05:19.520
to kind of how we're going to
be changing this process model?

00:05:19.520 --> 00:05:21.070
EMILY SCHECTER: So
one thing that's

00:05:21.070 --> 00:05:23.500
kind of a part of site
isolation is called

00:05:23.500 --> 00:05:25.092
cross origin read blocking.

00:05:25.092 --> 00:05:26.800
And there are some
things that developers

00:05:26.800 --> 00:05:29.080
need to do to sort
of take advantage

00:05:29.080 --> 00:05:32.000
of cross origin read blocking.

00:05:32.000 --> 00:05:34.310
We'll be talking about this
in our talk this afternoon.

00:05:34.310 --> 00:05:35.740
So everyone should
check that out.

00:05:35.740 --> 00:05:36.940
SURMA: So yeah, you should
definitely check that out.

00:05:36.940 --> 00:05:37.773
EMILY SCHECTER: Yep.

00:05:37.773 --> 00:05:39.380
SURMA: How much does--

00:05:39.380 --> 00:05:41.050
the one security
primitive on the web

00:05:41.050 --> 00:05:43.360
that I'm most [INAUDIBLE] CSP.

00:05:43.360 --> 00:05:46.600
How much does this have
to do with litigations

00:05:46.600 --> 00:05:48.160
against Spectre and Meltdown?

00:05:48.160 --> 00:05:50.875
Is this more an orthogonal
thing about cross-site scripting

00:05:50.875 --> 00:05:51.570
and things?

00:05:51.570 --> 00:05:53.320
Does it have anything
to do with Meltdown?

00:05:53.320 --> 00:05:55.100
CHRIS PALMER: No,
I don't think so.

00:05:55.100 --> 00:05:56.590
It won't help you
against Meltdown.

00:05:56.590 --> 00:05:57.755
It doesn't make it worse.

00:05:57.755 --> 00:05:58.630
It's just orthogonal.

00:05:58.630 --> 00:06:00.338
EMILY SCHECTER: But
it's still important.

00:06:00.338 --> 00:06:03.490
So everyone should be using
a content security policy.

00:06:03.490 --> 00:06:05.740
We'll also talk about that
in the talk this afternoon.

00:06:05.740 --> 00:06:07.536
SURMA: Well, there you go.

00:06:07.536 --> 00:06:09.910
JAKE: So it feels like a lot
of security problems we have

00:06:09.910 --> 00:06:14.530
on the web is down to things
that let one site make

00:06:14.530 --> 00:06:17.380
requests to another with
the other site's cookies

00:06:17.380 --> 00:06:19.060
without any permission for that.

00:06:19.060 --> 00:06:21.367
Is that just a mistake
we made with the web?

00:06:21.367 --> 00:06:23.200
Is that something that,
if we started again,

00:06:23.200 --> 00:06:24.579
we would just not allow?

00:06:24.579 --> 00:06:26.120
CHRIS PALMER: Ah,
that's a tough one.

00:06:26.120 --> 00:06:27.770
I spent some time
thinking about that.

00:06:27.770 --> 00:06:31.810
And I think that kind of
composability and embed-ability

00:06:31.810 --> 00:06:33.382
is a key goodness of the web.

00:06:33.382 --> 00:06:36.007
SURMA: I think we have on every
list of what the web superpower

00:06:36.007 --> 00:06:37.430
is, and like, the linkable--

00:06:37.430 --> 00:06:37.830
CHRIS PALMER: Yeah.

00:06:37.830 --> 00:06:39.370
SURMA: It's one of the
things we always list.

00:06:39.370 --> 00:06:41.078
CHRIS PALMER: That's
definitely on there.

00:06:41.078 --> 00:06:43.652
I think the thing
to do is, depending

00:06:43.652 --> 00:06:45.610
on the situation-- like
with cookies, you know,

00:06:45.610 --> 00:06:48.040
we're looking at the
same site cookies.

00:06:48.040 --> 00:06:49.010
The new thing.

00:06:49.010 --> 00:06:49.630
SURMA: Yeah.

00:06:49.630 --> 00:06:51.254
CHRIS PALMER: I think
that's a good way

00:06:51.254 --> 00:06:53.839
to solve that kind of problem,
because then the request is

00:06:53.839 --> 00:06:56.380
effectively anonymous, and it's
no different than what anyone

00:06:56.380 --> 00:06:57.166
could do.

00:06:57.166 --> 00:06:58.790
I think that deals
with it pretty well.

00:06:58.790 --> 00:07:00.340
JAKE: So same site
cookies is when,

00:07:00.340 --> 00:07:03.571
like, if I've included
an image on my site,

00:07:03.571 --> 00:07:05.070
it's going to get
my site's cookies.

00:07:05.070 --> 00:07:07.890
But if I include an image
to it to another site,

00:07:07.890 --> 00:07:09.424
this set of same
site cookies is not

00:07:09.424 --> 00:07:10.590
going to be sent with those.

00:07:10.590 --> 00:07:11.990
SURMA: It's not the same
site, therefore, no cookie.

00:07:11.990 --> 00:07:12.490
Right?

00:07:12.490 --> 00:07:13.316
JAKE: Right.

00:07:13.316 --> 00:07:14.830
SURMA: That's the
bottom line of it.

00:07:14.830 --> 00:07:16.989
JAKE: And it's the same
with navigation as well.

00:07:16.989 --> 00:07:17.530
Is that true?

00:07:17.530 --> 00:07:19.500
If I'm navigating from
one site to another,

00:07:19.500 --> 00:07:21.629
it doesn't send the
same site cookies?

00:07:21.629 --> 00:07:23.420
CHRIS PALMER: I don't
know if that is true.

00:07:23.420 --> 00:07:24.100
I think if you click the link--

00:07:24.100 --> 00:07:25.030
SURMA: That would be weird.

00:07:25.030 --> 00:07:25.530
Right?

00:07:25.530 --> 00:07:29.710
Like, if I linked from
my page to Facebook,

00:07:29.710 --> 00:07:31.290
you would suddenly
not be logged in?

00:07:31.290 --> 00:07:31.750
CHRIS PALMER: Right.

00:07:31.750 --> 00:07:33.250
Because the navigation
is a transfer

00:07:33.250 --> 00:07:36.552
of control to the new origin,
where it should be OK.

00:07:36.552 --> 00:07:39.010
SURMA: We'll link to an article
that explains what is true,

00:07:39.010 --> 00:07:41.190
because I don't know right now.

00:07:41.190 --> 00:07:43.500
JAKE: So one of the
things that has been,

00:07:43.500 --> 00:07:45.640
I guess, your team's
mission for so long

00:07:45.640 --> 00:07:49.132
is to drive the web off
HTTP and onto HTTPS.

00:07:49.132 --> 00:07:49.840
Are we don't yet?

00:07:49.840 --> 00:07:51.070
Is it 100%?

00:07:51.070 --> 00:07:53.480
EMILY SCHECTER: We
are not at 100% yet,

00:07:53.480 --> 00:07:55.510
but we are definitely
seeing a lot of movement

00:07:55.510 --> 00:07:57.190
up and to the right.

00:07:57.190 --> 00:08:00.370
We started publishing this
HTTPS transparency report back

00:08:00.370 --> 00:08:02.014
in, I think, early 2016.

00:08:02.014 --> 00:08:04.180
And what's pretty cool is
that we've been constantly

00:08:04.180 --> 00:08:06.890
updating that with
the amount of HTTP

00:08:06.890 --> 00:08:08.890
that we're actually seeing
being used in Chrome.

00:08:08.890 --> 00:08:10.180
SURMA: Do you remember
the current number?

00:08:10.180 --> 00:08:12.550
EMILY SCHECTER: I think
it's somewhere around 70%,

00:08:12.550 --> 00:08:14.140
but it kind of
varies per platform.

00:08:14.140 --> 00:08:15.848
SURMA: I mean, that's
pretty decent for--

00:08:15.848 --> 00:08:19.810
EMILY SCHECTER: We see it
definitely high on Chrome OS,

00:08:19.810 --> 00:08:21.510
probably more like 75% or 80%.

00:08:21.510 --> 00:08:22.190
SURMA: Well, I think
the problem we usually

00:08:22.190 --> 00:08:24.700
have is getting to the long
tail, which nobody maintains

00:08:24.700 --> 00:08:27.650
anymore, so that 70%
actually seems pretty good.

00:08:27.650 --> 00:08:30.705
JAKE: But even 70%, it doesn't
seem like that long ago.

00:08:30.705 --> 00:08:32.330
I mean, I've been at
Google five years,

00:08:32.330 --> 00:08:33.705
and it feels like
when I started,

00:08:33.705 --> 00:08:37.099
the HTTPS still felt like very
much in the minority of sites.

00:08:37.099 --> 00:08:38.140
EMILY SCHECTER: Oh, yeah.

00:08:38.140 --> 00:08:41.987
Yeah, I remember
giving talks on HTTPS.

00:08:41.987 --> 00:08:43.570
And I remember when
we first published

00:08:43.570 --> 00:08:45.790
the transparency report,
we have this list

00:08:45.790 --> 00:08:48.606
of the HTTPS status for the
top 100 sites on the web.

00:08:48.606 --> 00:08:50.230
When we first started
talking about it,

00:08:50.230 --> 00:08:55.150
it was maybe 20 or 25 sites
were using HTTPS by default,

00:08:55.150 --> 00:08:57.280
and now it's more like 80.

00:08:57.280 --> 00:09:01.720
So it's really just in the last
two, two and and a half years

00:09:01.720 --> 00:09:04.160
where we've seen this massive
increase in the top sites.

00:09:04.160 --> 00:09:04.860
JAKE: So how have
you achieved that?

00:09:04.860 --> 00:09:06.870
What have you done to
actually push that?

00:09:06.870 --> 00:09:08.710
SURMA: I bet it's encrypt.

00:09:08.710 --> 00:09:10.421
JAKE: Oh, spoiler alert.

00:09:10.421 --> 00:09:11.920
EMILY SCHECTER: One
is that I really

00:09:11.920 --> 00:09:14.620
think it's been a push around
the entire web ecosystem, not

00:09:14.620 --> 00:09:16.660
just Chrome, to
really help things.

00:09:16.660 --> 00:09:17.669
So you know--

00:09:17.669 --> 00:09:18.460
SURMA: That's true.

00:09:18.460 --> 00:09:19.330
EMILY SCHECTER: Let's
encrypt Started,

00:09:19.330 --> 00:09:21.460
which is this new, free,
automated certificate

00:09:21.460 --> 00:09:23.830
authority, which I think
made everything much

00:09:23.830 --> 00:09:25.630
easier and cheaper for people.

00:09:25.630 --> 00:09:26.142
SURMA: Yeah.

00:09:26.142 --> 00:09:27.850
EMILY SCHECTER: On
the Chrome thing side,

00:09:27.850 --> 00:09:31.140
one thing we've been doing is
changing the UI of HTTP sites

00:09:31.140 --> 00:09:33.160
to gradually mark
them as non-secure.

00:09:33.160 --> 00:09:35.410
And upcoming this July,
we were really excited.

00:09:35.410 --> 00:09:37.540
All the HTTP sites will
be marked as not secure.

00:09:37.540 --> 00:09:39.456
JAKE: It feels like the
right time to do that,

00:09:39.456 --> 00:09:42.060
to start marking things as
not secure, because even if--

00:09:42.060 --> 00:09:43.990
SURMA: It's not.

00:09:43.990 --> 00:09:44.680
JAKE: Yes, OK.

00:09:44.680 --> 00:09:45.939
But that's always been true.

00:09:45.939 --> 00:09:47.480
But now is the right
time to do that,

00:09:47.480 --> 00:09:49.220
because if we did
it five years ago,

00:09:49.220 --> 00:09:50.740
people would be seeing
it for all the sites,

00:09:50.740 --> 00:09:52.090
and they'd become
desensitized to it.

00:09:52.090 --> 00:09:52.940
EMILY SCHECTER: Yeah.

00:09:52.940 --> 00:09:53.890
JAKE: Is that why
we changed that?

00:09:53.890 --> 00:09:54.220
EMILY SCHECTER: Yeah.

00:09:54.220 --> 00:09:56.530
I think, you know, when
people see warnings too often,

00:09:56.530 --> 00:09:57.880
they get what's called
warning fatigue,

00:09:57.880 --> 00:09:59.755
where they stop paying
attention to warnings.

00:09:59.755 --> 00:10:02.500
And we also just thought that
it could make the web seem scary

00:10:02.500 --> 00:10:05.000
if suddenly tons of sites
that you're used to seeing,

00:10:05.000 --> 00:10:07.465
which are, in fact,
secure, now look scary.

00:10:07.465 --> 00:10:09.520
So we feel like
we've kind of reached

00:10:09.520 --> 00:10:11.050
this point, where
we can gradually

00:10:11.050 --> 00:10:12.670
turn around for everything.

00:10:12.670 --> 00:10:14.370
SPEAKER: They're
doing a sound test.

00:10:14.370 --> 00:10:16.880
SURMA: Well, can they not?

00:10:16.880 --> 00:10:17.760
[LAUGHING]

00:10:17.760 --> 00:10:19.520
SPEAKER: I think
we'll just keep going.

00:10:19.520 --> 00:10:20.350
CHRIS PALMER: I
think it's perfect.

00:10:20.350 --> 00:10:21.266
I would stick with it.

00:10:21.266 --> 00:10:23.446
I would keep that
part of the video.

00:10:23.446 --> 00:10:25.965
[REWINDING SOUNDS]

